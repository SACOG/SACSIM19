{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd310381",
   "metadata": {},
   "source": [
    "# Build Validation Table for NPMRDS\n",
    "For each of the 9 SACSIM time periods, provide:\n",
    "* Average speed\n",
    "* Number of epochs\n",
    "* Standard error of the speed (standard deviation / mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e346851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded all modules. ready to proceed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from time import perf_counter as perf\n",
    "\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import sqlalchemy as sqla # needed to run pandas df.to_sql() function\n",
    "    \n",
    "# extract SQL Server query results into a pandas dataframe   \n",
    "def sqlqry_to_df(query_str, dbname, servername='SQL-SVR', trustedconn='yes'):     \n",
    "\n",
    "    conn_str = \"DRIVER={ODBC Driver 17 for SQL Server};\" \\\n",
    "        f\"SERVER={servername};\" \\\n",
    "        f\"DATABASE={dbname};\" \\\n",
    "        f\"Trusted_Connection={trustedconn}\"\n",
    "        \n",
    "    conn_str = urllib.parse.quote_plus(conn_str)\n",
    "    engine = sqla.create_engine(f\"mssql+pyodbc:///?odbc_connect={conn_str}\")\n",
    "       \n",
    "    start_time = perf()\n",
    "\n",
    "    # create SQL table from the dataframe\n",
    "    print(\"Executing query. Results loading into dataframe...\")\n",
    "    df = pd.read_sql_query(sql=query_str, con=engine)\n",
    "    rowcnt = df.shape[0]\n",
    "    \n",
    "    et_mins = round((perf() - start_time) / 60, 2)\n",
    "    print(f\"Successfully executed query in {et_mins} minutes. {rowcnt} rows loaded into dataframe.\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_prd_df(qry_file, db_name, speed_tbl, tmc_tbl, prd_tag, prd_hrs):\n",
    "    \n",
    "    with open(qry_file, 'r') as f:\n",
    "        q_str = f.read()\n",
    "        \n",
    "    q_str_formatted = q_str.format(speed_tbl, prd_hrs, prd_tag, tmc_tbl)\n",
    "    \n",
    "    prd_df = sqlqry_to_df(q_str_formatted, db_name)\n",
    "    \n",
    "    return prd_df\n",
    "\n",
    "print(\"loaded all modules. ready to proceed.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c93c5a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading in data for h07...\n",
      "Executing query. Results loading into dataframe...\n",
      "Successfully executed query in 0.55 minutes. 7495 rows loaded into dataframe.\n",
      "loading in data for h08...\n",
      "Executing query. Results loading into dataframe...\n",
      "Successfully executed query in 0.41 minutes. 7495 rows loaded into dataframe.\n",
      "loading in data for h09...\n",
      "Executing query. Results loading into dataframe...\n",
      "Successfully executed query in 0.35 minutes. 7495 rows loaded into dataframe.\n",
      "loading in data for md5...\n",
      "Executing query. Results loading into dataframe...\n",
      "Successfully executed query in 0.45 minutes. 7495 rows loaded into dataframe.\n",
      "loading in data for h15...\n",
      "Executing query. Results loading into dataframe...\n",
      "Successfully executed query in 0.27 minutes. 7495 rows loaded into dataframe.\n",
      "loading in data for h16...\n",
      "Executing query. Results loading into dataframe...\n",
      "Successfully executed query in 0.25 minutes. 7495 rows loaded into dataframe.\n",
      "loading in data for h17...\n",
      "Executing query. Results loading into dataframe...\n",
      "Successfully executed query in 0.25 minutes. 7495 rows loaded into dataframe.\n",
      "loading in data for ev2...\n",
      "Executing query. Results loading into dataframe...\n",
      "Successfully executed query in 0.26 minutes. 7495 rows loaded into dataframe.\n",
      "loading in data for n11...\n",
      "Executing query. Results loading into dataframe...\n",
      "Successfully executed query in 0.39 minutes. 7495 rows loaded into dataframe.\n",
      "successfully created dataframe for speeds in all sacsim time periods.\n"
     ]
    }
   ],
   "source": [
    "query_file = 'cong_speed_model_prds.sql'\n",
    "\n",
    "db = 'NPMRDS'\n",
    "speed_data_year = 2017\n",
    "TMC_yr = 2020\n",
    "tbl_speeds = 'npmrds_2017_alltmc_paxtruck_comb'\n",
    "tbl_tmcs = 'npmrds_2020_alltmc_txt'\n",
    "join_key = 'tmc'\n",
    "\n",
    "prds = {'h07':[7], 'h08':[8], 'h09':[9], 'md5':[10, 11, 12, 13, 14], \n",
    "        'h15':[15], 'h16':[16], 'h17':[17], 'ev2':[18, 19], \n",
    "        'n11': [20, 21, 22, 23, 0, 1, 2, 3, 4, 5, 6]}\n",
    "\n",
    "df_master = pd.DataFrame()\n",
    "\n",
    "for i, prdtag in enumerate(prds.keys()):\n",
    "    print(f\"loading in data for {prdtag}...\")\n",
    "    prd_hours = ','.join(str(i) for i in prds[prdtag])\n",
    "    if i == 0:\n",
    "        df_master = get_prd_df(qry_file=query_file, db_name=db,\n",
    "                               speed_tbl=tbl_speeds, tmc_tbl=tbl_tmcs, \n",
    "                               prd_tag=prdtag, prd_hrs=prd_hours)\n",
    "    else:\n",
    "        df_p = get_prd_df(qry_file=query_file, db_name=db,\n",
    "                               speed_tbl=tbl_speeds, tmc_tbl=tbl_tmcs, \n",
    "                               prd_tag=prdtag, prd_hrs=prd_hours)\n",
    "        \n",
    "        df_master = df_master.merge(df_p, on=join_key)\n",
    "        \n",
    "        \n",
    "print(\"successfully created dataframe for speeds in all sacsim time periods.\")\n",
    "        \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3206e4df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q:\\\\SACSIM23\\\\Network\\\\SM23GIS\\\\SM23Testing.gdb\\\\InrixPrdSpd_2017on2020TMC20220119_1050'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join to link feature class and export to GIS feature class\n",
    "from arcgis.features import GeoAccessor, GeoSeriesAccessor\n",
    "import datetime as dt\n",
    "\n",
    "input_link_fc = r'Q:\\SACSIM23\\Network\\SM23GIS\\MN_link_forConflation_YZ\\ConflationResults.gdb\\conflation_INRIX_20211207'\n",
    "links_jnky = 'Tmc'\n",
    "link_fc_cols = ['OBJECTID', 'A', 'B', 'A_B', 'CAPC20', 'NAME', links_jnky,\n",
    "       'RoadName', 'FwyTag', 'RoadNumber', 'Type', 'Mis_cf_check', 'SHAPE']\n",
    "\n",
    "\n",
    "output_fgdb = r'Q:\\SACSIM23\\Network\\SM23GIS\\SM23Testing.gdb'\n",
    "\n",
    "#-----------RUN script-----------\n",
    "sufx = str(dt.datetime.now().strftime('%Y%m%d_%H%M'))\n",
    "\n",
    "output_fc_name = f'InrixPrdSpd_{speed_data_year}on{TMC_yr}TMC{sufx}'\n",
    "\n",
    "\n",
    "sedf_links = pd.DataFrame.spatial.from_featureclass(input_link_fc)\n",
    "sedf_links = sedf_links[link_fc_cols]\n",
    "sedf_links = sedf_links.merge(df_master, how='left', left_on=links_jnky, right_on=join_key)\n",
    "sedf_links.spatial.to_featureclass(os.path.join(output_fgdb, output_fc_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83724906-6836-4e07-ad96-f4816ff25331",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
